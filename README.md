#  WhatsApp Conversational LoRA Trainer â€” v1.0

This project automates WhatsApp message responses using an Ollama language model running locally as a backend and integrates [Baileys](https://github.com/WhiskeySockets/Baileys) â€” a WhatsApp Web API client library.

---

##  Features (v1)

- ğŸ¤– Message auto-response via locally hosted Ollama model.
- ğŸ“„ Session-wise message logging to `.jsonl` files.
- ğŸ”§ Configurable bot behavior via `.env` flags.
- ğŸ”Œ Pluggable Ollama model via REST API integration.
- ğŸ“ Log rotation (planned)
- ğŸ“Š Dataset preprocessing for LoRA fine-tuning (planned)

---

## ğŸ›  Installation

###  Clone and Install Dependencies

```
git clone https://github.com/hillolborah/WhatsAppAutomation.git
cd WhatsAppAutomation
npm install
```

## âš™ï¸ Ollama Setup

Ensure [Ollama](https://ollama.com/download) is installed and running locally.

### ğŸ“„ Check Ollama service:

```
systemctl status ollama
```

## List installed models
```
ollama list
```


##Run an Ollama model
```
ollama run phi4
```


## ğŸ“² WhatsApp Bot Setup

### 1ï¸âƒ£ Configure Environment

Navigate to the project root and set your environment flags:

```
cd WhatsAppAutomation
nano .env
```
### 2ï¸âƒ£ Start the Bot
```
node whatsapp-bot/src/index.js
```




